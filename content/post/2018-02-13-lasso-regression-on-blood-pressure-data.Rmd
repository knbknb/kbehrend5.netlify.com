---
title: Lasso regression on Blood Pressure data
author: Knut Behrends
date: '2018-02-13'
slug: bloodpressure-lasso
categories: [health]
tags: [health, medicine]
draft: yes
output:
  html_document:
    toc: no
    css: styles.css
    fig_caption: yes
    keep_md: no
image: /static/img/hugo-gopher.png
banner: img/post/thumb/hugo-logo.png
summary: ''
keywords:
  - Personal-Blog
  - Fun
  - rstats
  - health
---


```{r setup, include=FALSE}
library(knitr)
opts_chunk$set(cache = TRUE, warning = FALSE, message = FALSE, 
               echo = FALSE, tidy = FALSE, width = 7, fig.width=9)
options(digits = 3, tibble.print_min = 6)
options(knitr.table.format = "html") 
library(kableExtra)
```
```{r pkgs1}
library(mice)  # imputation

library(NHANES) # Body Shape + related measurements from 10000 US citizens
data(NHANES)
library(rvest)
library(tidyverse)
library(ggthemes)
theme_set(theme_bw())
scale_colour_discrete <- function(...) scale_color_brewer(palette="Set1")

```

#### Lasso Regression on Blood Pressure Data (NHANES Dataset)


```{r abstr, echo=FALSE}
htmltools::HTML('<div class="alert alert-info"><b>Performing Lasso Regression on anonymized data from 10000 people representing the general US Population</b>. Actually I will also try out other model selection techniques.
</div>')
```
This is a follow-up to [an exploratory data-analysis post](/post/2018/02/bloodpressure-nhanes) of mine. When I was nearly done with writing that post, some new questions came to my mind.

In the preceding blogpost I noticed that Systolic Blood Pressure is correlated with age and weight, but the relationship is complicated: the trend was noisy and the correlation was weak, and interaction term in the linear model seems to play an important role. 

Here I'll continue with exploratory analysis, so there is not really a new hypothesis. More basically, can I determine some other variables (out of the `r ncol(NHANES)`) that are also influencing the Blood Pressure in some way?

I am not trying to do groundbreaking medical research here. Hey I'm just a blogger, playing with a dataset for personal entertainment, trying out some of those fancy Machine Learning algorithms that I encountered during MOOC homework assignments. This time I'll try these techniques out on larger datasets that *I* find interesting.


#### NHANES dataset

NHANES is  the US National Health and Nutrition Examination Study. It is a carefully curated, larger medical survey aiming to get a representative sample of the general US population. The survey is carried out periodically.

The [*NHANES* dataset](https://www.cdc.gov/nchs/nhanes/participant_video.htm) is available as an R package on [CRAN](https://cran.r-project.org/package=NHANES). I have used package version 2.1.0, specifically "NHANES 2009-2012 with adjusted weighting". This dataset contains data from two collection periods, 2009-2010 and 2011-2012.

Obligatory Disclaimer (from the Package Documentation):

*Please note that the data sets provided in this package are derived from the NHANES database and have been adapted for educational purposes. As such, they are NOT suitable for use as a research database.*

#### Feature Engineering
These are  the column names and some other important metadata of the NHANES dataset. These metadata are, for example, the unique distinct values of columns where it makes sense to report them (e.g. male/female for column "gender") 


```{r names_defs}
x <- read_html(x = here::here("data_private/nhanes_datadict_raw.html"))
dls <- html_nodes(x, xpath="//dl") 
nhanes_defs = data.frame()
dl <- dls[[1]]
dts <- html_nodes(dl, xpath="//dt")  
dds <- html_nodes(dl, xpath="//dd")
nhanes_defs <- data_frame(
                  "Column" = dts %>% 
                           html_nodes(xpath='//dt')%>% html_text(),
                   "Meaning" = dds %>% html_nodes(xpath='//dd')%>% 
                           html_text() %>% str_trim() %>% 
                           str_replace_all("\t", " ") %>%  
                           str_replace("\"","")
                   )
```

```{r}

action1 <- "drop"
action2 <- "Yes/No"

nhanes_defs <- nhanes_defs %>%
        mutate(Action= case_when(
# (str_detect(Meaning, "Yes") == TRUE)  & 
#  str_detect(Meaning, "No") == TRUE ~ action2, 
         Column == "ID" ~ action1,
         Column == "AgeMonths" ~ action1,
         Column == "AgeDecade" ~ action1,
         Column == "Race3" ~ action1,
         Column == "Education" ~ action1,
         Column == "MaritalStatus" ~ action1,
         Column == "Length" ~ action1,
         Column == "HeadCirc" ~ action1,
         Column == "MaritalStatus" ~ action1,
         Column == "BMICatUnder20yrs" ~ action1,
         Column == "BMI_WHO" ~ action1,
         str_detect(Column, pattern=regex("^BP")) == TRUE &
         str_detect(Column, pattern=regex("Ave")) == FALSE ~ action1,
         # Column == "nPregnancies" ~ action1,
         # Column == "nBabies" ~ action1,
         # Column == "PregnantNow" ~ action1,
         # Column == "Age1stBaby" ~ action1,
         str_detect(Column, "WTINT2YR") == TRUE ~ action1,
         Column == "TVHrsDayChild" ~ action1,
         Column == "CompHrsDayChild" ~ action1,
#         str_detect(Column, pattern=regex("TVHrs|CompHrs|AgeDecade")) ==
#                 TRUE ~ action1,
        
         TRUE ~ ""))

```

```{r tabledef, cache=FALSE}

knitr::kable(nhanes_defs, row.names = 1, 
              caption = "Column names in NHANES data set,\
              and columns that will be dropped") %>% 
        kable_styling(bootstrap_options = 
                c("striped", "hover"))


```

```{r}

drop_cols <- nhanes_defs %>% 
        filter(Action == action1) %>% select(Column) %>%
        as_vector()

# factor_cols <- nhanes_defs %>% 
#         filter(Action == action2) %>% select(Column) %>% 
#         as_vector()
#dfr <- NHANES %>% select(Age, AgeDecade) %>% filter(is.na(AgeDecade))


```

More Feature Engineering Measures:

- Remove people less than 20 years of age
- Remove columns, marked as "drop" in table 1 (measured for child/youth-only, etc).
- Impute missing values with "mice" method (Multiple Imputation by Chain Equation)


```{r imputed, echo=TRUE, cache=TRUE}
NHANES <- NHANES %>% 
        filter(Age >= 20) %>% 
        select(setdiff(colnames(NHANES), drop_cols) )

NHimp <- "../../data_private/NHANES-imputed.rds"

if (file.exists(NHimp)){
        imputed <- readRDS(NHimp)
} else {
        #set.seed(47)
        imputed <- mice::complete(mice(NHANES))
        saveRDS(imputed, file = NHimp)
}


```

NHANES Data after Feature Engineering: no more NAs in any column.


```{r contents}
Hmisc::contents(imputed)
```




Model Selection Using a Validation Set
---------------------------------------
Lets make a training and validation set, so that we can choose a good subset model.
We will do it using a slightly different approach from what was done in the the book.

```{r trainset, eval=TRUE}
#dim(imputed)

set.seed(1)
# take 80% of observations,
ntrain <- as.integer(nrow(imputed) * 0.8)
train  <- sample(seq(nrow(imputed)), ntrain, replace = FALSE)

```

```{r usetrainset, eval=FALSE}
# use training data subset
regfit.fwd <- regsubsets(BPSysAve~., data = imputed[train, ], 
                         nvmax = 19, method = "forward")
```

Now we will make predictions on the observations not used for training. We know there are 19 models, so we set up some vectors to record the errors. We have to do a bit of work here, because there is no predict method for `regsubsets`.

```{r plotregsubsets, eval=FALSE}
val.errors <- rep(NA, 19)
x.test <- model.matrix(BPSysAve~., data = imputed[-train, ]) # notice the -index!
for (i in 1:19) {
  # complex loop
  coefi <- coef(regfit.fwd, id = i)
  pred <- x.test[, names(coefi)] %*% coefi
  val.errors[i] <- mean((imputed$BPSysAve[-train] - pred) ^ 2)
}
# ylim=c(300,400),
plot(sqrt(val.errors), ylab = "Root MSE", pch = 19, type = "b")
# remove NULL model
points(sqrt(regfit.fwd$rss[-1] / ntrain), col = "blue", pch = 19, type = "b")
legend("topright", legend = c("Training", "Validation"), col = c("blue", "black"), pch = 19)
```
As we expect, the training error goes down monotonically as the model gets bigger, but not so 
for the validation error.

This was a little tedious - not having a predict method for `regsubsets`. So we will write one!
```{r eval=FALSE}
## make  a generic function
# id is the id of the model
predict.regsubsets <- function(object, newdata, id, ...) {
  form  <- as.formula(object$call[[2]])
  mat   <- model.matrix(form, newdata)
  coefi <- coef(object, id = id)
  mat[, names(coefi)] %*% coefi
}
```




Model Selection by Cross-Validation
-----------------------------------
We will do 10-fold cross-validation. Its really easy!
```{r eval=FALSE}
set.seed(11)
# create a vector of nrows, fill it with an equal number of each 1s, 2s, ... 10s.
folds <- sample(rep(1:10, length = nrow(imputed)))
# folds
table(folds)
cv.errors <- matrix(NA, 10, 19)
for (k in 1:10) {
  # leave the k-fold out
  best.fit <- regsubsets(BPSysAve~., 
                         data = imputed[folds != k, ], 
                         nvmax = 19, method = "forward")
  for (i in 1:19) {
    # call predict.subsets via generic call
    pred <- predict(best.fit, imputed[folds == k, ], id = i)
    cv.errors[k, i] <- mean((imputed$BPSysAve[folds == k] - pred) ^ 2)
  }
}
# take the column means
rmse.cv <- sqrt(apply(cv.errors, 2, mean))
plot(rmse.cv, pch = 19, type = "b")
#a little bit smoother than the other more jumpy plots
```



Ridge Regression and the Lasso
-------------------------------
We will use the package `glmnet`, which does not use the model formula language, so we will set up a
matrix `x` of predictors and a response vector `y`.
```{r glmnet}
library(glmnet)
x = model.matrix(BPSysAve ~ . - 1, data = imputed) 
y = imputed$BPSysAve
```
First we will fit a ridge-regression model. This is achieved by calling `glmnet` with `alpha=0` (see the helpfile). There is also a `cv.glmnet` function which will do the cross-validation for us.

- 0 : ridge
- 1 : lasso
- 0.x  : elasticnet

```{r plotridge}
fit.ridge <- glmnet(x, y, alpha = 0)
plot(fit.ridge, xvar = "lambda", label = TRUE)
cv.ridge <- cv.glmnet(x, y, alpha = 0)
plot(cv.ridge)
```

Now we fit a lasso model; for this we use the default `alpha=1`

```{r lasso}
fit.lasso <- glmnet(x, y)
plot(fit.lasso, xvar = "lambda", label = TRUE)
plot(fit.lasso, xvar = "dev", label = TRUE)

cv.lasso <- cv.glmnet(x, y)
leg1str <- sprintf("log of best Lambda = %.3f  (%.3f)", 
                   log(cv.lasso$lambda.min), cv.lasso$lambda.min)
leg2str <- sprintf("log of best Lambda + 1 SE = %.3f (%.3f)", 
                   log(cv.lasso$lambda.1se), cv.lasso$lambda.1se)
plot(cv.lasso)
legend("topleft", legend = str_c(leg1str, leg2str, sep="; "), pch = 1)
title(main = paste(c(leg1str, leg2str)))
# pick/show  the coefficients vector from the best model
coef(cv.lasso) # lambda = 69.01 => 6 coefs

```

 Suppose we want to use our earlier train/validation division to select the `lambda` for the lasso.
 This is easy to do.
```{r predlasso}
# train was defined above
lasso.tr <- glmnet(x[train, ], y[train])
lasso.tr # print until it model no longer really changes (~ 90 lines here)
pred <- predict(lasso.tr, x[-train, ])
dim(pred)
# vector - matrix
# this recycles the vector 89 times!
# (using R's implicit-wrap-around feature)
rmse <- sqrt(apply((y[-train] - pred) ^ 2, 2, mean))
plot(log(lasso.tr$lambda), rmse, type = "b", xlab = "Log(lambda)")
# extract the best lambda: sort asc, pick first
lam.best <- lasso.tr$lambda[order(rmse)[1]]
lam.best
coef(lasso.tr, s = lam.best)
```



```{r htmltools}
htmltools::HTML('<div class="alert alert-info"><b>What I&apos; learned from doing this:</b>
<ul>
<li>Applied Model Selection techniques, a little bit more independently than before 
<li>Played a bit with the `ggvis` package, which generates vector graphics instead of SVGs 
</ul>
</div>')

```

<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on Knut Behrends Personal Blog, v3</title>
    <link>/post/</link>
    <description>Recent content in Posts on Knut Behrends Personal Blog, v3</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>&amp;copy;2018 Knut Behrends</copyright>
    <lastBuildDate>Sat, 20 Jan 2018 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="/post/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Global interest in Bitcoin over Time</title>
      <link>/post/2018/01/bitcoin-interest/</link>
      <pubDate>Sat, 20 Jan 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/2018/01/bitcoin-interest/</guid>
      <description>Abstract: Bitcoin. Visualizing (1) Wikipedia Pageviews, (2) Google Searches and (3) Exchange Rates from 2015 to early 2018. Simple timeseries plots (created from Web-API data) show that these three are strongly correlated.  In this post I’ll analyse global interest in Bitcoin and Ethereum over time, according to accesses to Wikipedia articles and as Google Searches. At this time, no API keys and authentication are necessary.
The end of the year 2017 saw the “Bitcoin Bubble”, a period of one month where 1 Bitcoin was traded for up to $20000 on most exchanges.</description>
    </item>
    
    <item>
      <title>Drawing a network with &#34;ggraph&#34; and &#34;tidygraph&#34;</title>
      <link>/post/2018/01/drawing-a-figshare-network-with-ggraph-and-tidygraph/</link>
      <pubDate>Tue, 16 Jan 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/2018/01/drawing-a-figshare-network-with-ggraph-and-tidygraph/</guid>
      <description>NOTE This blogpost is inspired by this one: Drawing a network with &#34;ggraph&#34; and &#34;tidygraph&#34; by Ken Butler 
 I’m trying to learn the differences between using the igraph library directly and the new packages ggraph and tidygraph.
Introduction Thomas Lin Pedersen is the author of a lot of packages, including two that deal with graphs (in the sense of networks), tidygraph for storing and handling graphs, and ggraph for drawing them, ggplot-style.</description>
    </item>
    
    <item>
      <title>Comparing 33C3 and 34C3 tweets</title>
      <link>/post/2018/01/tweets-33c3-vs-33c4/</link>
      <pubDate>Sun, 07 Jan 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/2018/01/tweets-33c3-vs-33c4/</guid>
      <description>Why this analysis? There are two reasons:
 learn to process Twitter data at scale (~100MB-1GB/file - that’s large enough for me) get more info from/about the inspiring tweets from the CCC community  (This blogpost ist still a DRAFT - I want to publish quickly, even when an analysis is incomplete, or the text is a bit rough in places)
 Background Occasionally, over the last two years, I have gathered data from the Twitter Streaming API.</description>
    </item>
    
    <item>
      <title>Some Gists</title>
      <link>/post/2018/01/some-gists/</link>
      <pubDate>Sat, 06 Jan 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/2018/01/some-gists/</guid>
      <description>Link Collection for my own personal use Github ‘Gists’ are code samples that are too short for, or not worth creating a new standalone repository.
For example
 One-off scripts unfinished/half-working scripts forked github gists from other people copies of codesamples from other people, slightly edited or customized  This webpage is just for my own personal use, a reminder for myself.
For now, I list only the links to the gists.</description>
    </item>
    
    <item>
      <title>Constructing a tiny social-network visualization from the #Rstats hashtag</title>
      <link>/post/2018/01/constructing-a-tiny-social-network-visualization-from-the-rstats-hashtag/</link>
      <pubDate>Mon, 01 Jan 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/2018/01/constructing-a-tiny-social-network-visualization-from-the-rstats-hashtag/</guid>
      <description>(Under Construction) In 2016, I was harvesting tweets from the Twitter streaming API. I’ve used the #rstats hashtag as the search filter. This hashtag is commonly used by the R community on Twitter. Tag #rstats is more descriptive than the too short, unusable, #R hashtag which may not even be a valid filter expression.
Here I do some exploratory analysis of these ~ 1000 tweets, and I visualize the interactions (the “mentions”) of the active Twitter users as a directed graph.</description>
    </item>
    
    <item>
      <title>Soccer-Database: Extracting goal data from XML fragments</title>
      <link>/post/2017/12/database/</link>
      <pubDate>Sun, 17 Dec 2017 00:00:00 +0000</pubDate>
      
      <guid>/post/2017/12/database/</guid>
      <description>This is part 2 of a 3-part series about Statistical Analysis of Soccer data.
 Part 1 shows the database diagram of the Sqlite database mentioned below. Part 2 (this page) describes how to preprocess some text data that was stored in an cryptic format inside the database Part 3 (not written yet) describes some statistical analysis of some aspect of this dataset.  Dataset The dataset used here is the “European Soccer Database” - 25k+ matches, players &amp;amp; teams attributes for European Professional Football from Kaggle.</description>
    </item>
    
    <item>
      <title>Soccer-Database: Generating schema diagrams</title>
      <link>/post/2017/12/soccerdb-schema-diagrams/</link>
      <pubDate>Sun, 17 Dec 2017 00:00:00 +0000</pubDate>
      
      <guid>/post/2017/12/soccerdb-schema-diagrams/</guid>
      <description>This is part 1 of a 3-part series of small blog posts about my first attempts at Bayesian Analysis of Soccer data.
In order to get started I had to invest much more effort than expected into cleaning the data and getting familiar with it.
tl;dr: This blog post shows 3 times the same database diagram, at varying levels of detail.
Dataset The dataset used here is the &amp;ldquo;European Soccer Database&amp;rdquo; - 25k+ matches, players &amp;amp; teams attributes for European Professional Football from Kaggle.</description>
    </item>
    
    <item>
      <title>Learning jq</title>
      <link>/post/2017/12/learning-jq/</link>
      <pubDate>Sat, 16 Dec 2017 00:00:00 +0000</pubDate>
      
      <guid>/post/2017/12/learning-jq/</guid>
      <description>A grabbag of commands  Some notes about learning jq, the lightweight and flexible command-line JSON processor. I&amp;apos;ll extend and improve this blog post in the next months, in Q1/2018. This page is a notepad for my own use, it has not the purpose to teach anyone. I need to be fluent with the JSON parsing tool jq. Very often I have to interact with JSON data: When I interact with APIs, when parsing scraped Twitter data, when doing SPARQL queries…</description>
    </item>
    
    <item>
      <title>Soccer Euro 2016 - Betting At My Workplace - Part 2</title>
      <link>/post/2017/12/soccer-world-cup-bets-part-ii/</link>
      <pubDate>Sat, 09 Dec 2017 00:00:00 +0000</pubDate>
      
      <guid>/post/2017/12/soccer-world-cup-bets-part-ii/</guid>
      <description>Soccer championship Euro 2016 - A weekend project, from July 2016 Continued from a previous blog post, that explained the data preprocessing steps.
 I wrote this in July 2016 to make myself familiar with the R package ggplot2, and other tidyverse packages. This post contains exploratory analysis of an Euro 2016 Betting Game. Predictions were made, just for fun and a small amount of prize money, by a group of players at my workplace.</description>
    </item>
    
    <item>
      <title>Soccer Euro 2016 - Betting At My Workplace - Part I</title>
      <link>/post/2017/12/soccer-world-cup-bets-part-i/</link>
      <pubDate>Sat, 09 Dec 2017 00:00:00 +0000</pubDate>
      
      <guid>/post/2017/12/soccer-world-cup-bets-part-i/</guid>
      <description>Soccer championship Euro 2016 - A weekend project, from July 2016 This is the data-preprocessing part of a blog post that has most of its visual content in a second part.
Part 1: preprocessing the data  I wrote this in July 2016, to make myself familiar with the R packages ggplot2 and other tidyverse packages. Exploratory Analysis of an Euro 2016 Betting Game. Predictions were made, just for fun (and a small amount of prize money), by a group of players (colleagues, their friends and family members) from my workplace in Germany.</description>
    </item>
    
    <item>
      <title>Body Height and BMI in European Soccer Players over the years 2008-2016</title>
      <link>/post/2017/12/body-height-and-bmi-in-european-soccer-players-over-the-years-2008-2016/</link>
      <pubDate>Mon, 04 Dec 2017 00:00:00 +0000</pubDate>
      
      <guid>/post/2017/12/body-height-and-bmi-in-european-soccer-players-over-the-years-2008-2016/</guid>
      <description>Change of body parameters in soccer players  How did body mass index and body size of professional football players change over the years? Body size, not so much. It has stayed rather constant between 2008 and 2016. Average height might have even fallen a little bit. Body weight and, correspondingly, Body Mass Index on the other hand, have fallen even more. This means the top clubs want thinner players. It also means, in soccer, possibilities to increase the athleticism of players is limited.</description>
    </item>
    
    <item>
      <title>The oldest active European Soccer Player in season 2008</title>
      <link>/post/2017/12/the-oldest-active-european-soccer-player-in-season-2008/</link>
      <pubDate>Sun, 03 Dec 2017 00:00:00 +0000</pubDate>
      
      <guid>/post/2017/12/the-oldest-active-european-soccer-player-in-season-2008/</guid>
      <description>Still playing with a Soccer Database from Kaggle.com  As an exercise, I wanted to find the oldest players participating in any match. During my analysis I also learned something about the data quality of this Kaggle dataset.
 As mentioned in a previous blogpost, I’ve downloaded a zipfile (36 MB) with Football data from data science community Kaggle.com. The archive contained an SQLite Database.
library(DBI) con &amp;lt;- dbConnect(odbc::odbc(), &amp;quot;well-sqlite-footballdb&amp;quot;) For the sake of brevity, to see the R packages I’ve included to process the data, see the previous blogpost.</description>
    </item>
    
    <item>
      <title>European Soccer Players and their BMI</title>
      <link>/post/2017/11/european-soccer-players-and-their-bmi/</link>
      <pubDate>Wed, 22 Nov 2017 00:00:00 +0000</pubDate>
      
      <guid>/post/2017/11/european-soccer-players-and-their-bmi/</guid>
      <description>Playing with a Soccer Database from Kaggle.com Recently I’ve downloaded as a zipfile (36 MB) from data science community Kaggle.com.
This zipfile contains a single file, a 313 MB sqlite Database. Let’s take a peek what’s inside:
Create connection to football DB
library(DBI) con &amp;lt;- dbConnect(odbc::odbc(), &amp;quot;well-sqlite-footballdb&amp;quot;) Read in R packages necessary to load the data:
# tidyverse packages library(dplyr, warn.conflicts = FALSE) # library(purrr) # functional programming library(stringr) library(lubridate) # strings to datetime library(ggplot2) library(NHANES) # US health data data(NHANES) theme_set(theme_bw()) The database consists of 7 tables.</description>
    </item>
    
  </channel>
</rss>